---
title: タスク トリガーとしての LUIS 認識エンジンの定義 | Microsoft Docs
description: LUIS.ai を使用して、タスク トリガーとして言語解釈認識エンジンを設定する方法を説明します。
author: vkannan
manager: kamrani
ms.topic: article
ms.prod: bot-framework
ms.date: 12/13/2017
ROBOTS: NoIndex, NoFollow
ms.openlocfilehash: 39fe222fb1d54346b33617c425b1fdf2d56daa0d
ms.sourcegitcommit: f576981342fb3361216675815714e24281e20ddf
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 07/18/2018
ms.locfileid: "39304172"
---
# <a name="define-a-luis-recognizer-as-task-trigger"></a>タスク トリガーとしての LUIS 認識エンジンの定義
> [!IMPORTANT]
> Conversation Designer は、一部のお客様はまだご利用いただけません。 Conversation Designer の使用可能性については、今年中に詳細をお知らせする予定です。

ほとんどの場合、ユーザーは自然言語でタスクを実行する意図を示します。 Conversation Designer を使用すると、<a href="https://luis.ai" target="_blank">LUIS.ai</a> によって強化されたボットの自然言語解釈モデルを簡単に設定できます。

これを行うには、トリガーの種類 **[ユーザーが何かを発言または入力する]** を選択します。 これにより、**意図**の名前を指定するためのオプションが使用できるようになります。 

既存の意図を検索したり、**[言語の意図の選択]** フィールドに新しい意図を作成したりできます。

## <a name="create-a-new-intent"></a>新しい意図を作成する

新しい意図を作成するには、意図の名前を入力し、**[新しい意図の作成]** をクリックします。 この特定のタスクをトリガーするためにユーザーが言いそうな事柄を示す発話の例を入力します。

たとえば、カフェ ボットはユーザーの近くにあるカフェの場所を検索するタスクを実行できる必要があります。 このシナリオを処理するには、**[ユーザーが何かを発言または入力する]** を選択して、**[意図の名前]** を [LocationNearMe] に設定します。 次に、この意図の発話の例を提供します。 例:  
- *近くの場所を検索*
- *近くにあるカフェの場所を検索*
- *Redmond の店舗は営業中ですか*
- *シアトルに店舗はありますか*
- *どの場所のカフェが現在営業中ですか*
- *どこで食べ物を入手できますか*
- *何か食べたいです*
- *お腹が空きました*

この特定のタスクをトリガーするユーザーの意図を示すのに役立つ、思いつく限り多くの発話を入力します。

## <a name="default-intents-provisioned-for-your-bot"></a>ボット用にプロビジョニングされた既定の意図

既定では、ボットは、4 つの意図をプロビジョニングされています。 
- **なし**: これはボットのフォールバック (既定値) の意図です。 この意図を使用すると、ボットがまだ応答方法を認識していない事柄をキャプチャするのに役立ちます。
- **ヘルプ**: ユーザーがヘルプを必要としているかどうかを判断するのに役立つ発話の例を設定します。 *助けて、ヘルプが必要です、なんと言ったらいいのか、困っています*など。
- **あいさつ**: *やあ、こんにちは、おはよう、ボットのご機嫌はいかが*など、あいさつの意図に一致させるために役立つ発話の例を設定します。
- **キャンセル**: キャンセルの意図の発話例を設定します。 *ストップ、キャンセルして、しません、元に戻して*など。

## <a name="create-and-label-entities"></a>エンティティの作成とラベル付け

ユーザーの意図を判断するのに役立つこととは別に、言語解釈はタスクに関連する関心のある特定のエンティティを決定する際にも役立ちます。 たとえば、ユーザーが「*Redmond の近くのカフェの場所を検索*」と発言した場合、***location*** エンティティの考えられる値として *Redmond* を抽出することができます。 

タスクのエンティティを設定するには、**発話**文字列から、エンティティ値の例にする必要がある発話の一部を選択します。 これを既存のエンティティに割り当てるか、新規に作成します。 新しいエンティティを作成するには、エンティティの名前を **[検索または作成]** フィールドに入力し、**[新しいエンティティの作成]** をクリックします。 

# <a name="supported-entity-types"></a>サポートされているエンティティ型

言語解釈では、さまざまな型のエンティティを作成することができます。 新しいエンティティの作成時には `type` を指定する必要があります。 

使用可能な型は次のとおりです。

- **Simple**: これは*既定*の型です。
- **List**: エンティティに有限の使用可能な値のセットがある場合は、この型を使用します。 例: *Color*、*City*。
- **Hierarchical**: この型を使用して、親子関係のあるエンティティを作成します。 例: *fromCity* と *toCity* の両方に親として *City* エンティティがあります。
- **Composite**: この型を使用して、意味のある単位を構成する値のグループを作成します。 例: *City* と *State* が一体となって *Location* エンティティを構成します。

<!-- # pre-built entity types TBD -->

# <a name="entities-in-use"></a>使用中のエンティティ

エンティティを作成して言語解釈セクションに追加すると、この特定のタスクが使用するエンティティのリストを使用して **[使用中のエンティティ]** テーブルが更新されます。 リストには、このタスクで使用されるその他のエンティティを手動で追加することができます。 

使用できるオプションは次のとおりです。

- **コード**: これは、カスタム スクリプトで作成されるエンティティです。 ここで指定すると、IntelliSense のような作成機能に役立ちます。

<!-- # Use as help tip TBD  -->

## <a name="next-step"></a>次のステップ
> [!div class="nextstepaction"]
> [コード認識エンジン](conversation-designer-code-recognizer.md)
