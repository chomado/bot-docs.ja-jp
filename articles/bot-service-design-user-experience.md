---
title: ユーザー エクスペリエンスを設計する | Microsoft Docs
description: リッチ ユーザー コントロール、自然言語の理解、および音声を使用して、魅力的なユーザー エクスペリエンスを提供するようにボットを設計する方法について説明します。
keywords: 概要, 設計, ユーザー エクスペリエンス, UX, リッチ ユーザー コントロール
author: matvelloso
ms.author: mateusv
manager: kamrani
ms.topic: article
ms.service: bot-service
ms.subservice: sdk
ms.date: 09/20/2018
ms.openlocfilehash: 0b5bc1e82b6ef2dc5550fcaa5db176d06a7d2ea7
ms.sourcegitcommit: b78fe3d8dd604c4f7233740658a229e85b8535dd
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 10/24/2018
ms.locfileid: "49999699"
---
# <a name="design-the-user-experience"></a>ユーザー エクスペリエンスを設計する

テキスト、ボタン、画像、カルーセルまたはリスト形式で表示されるリッチ カードなど、さまざまな機能を備えたボットを作成できます。 ただし、Facebook、Slack、Skype などの各チャンネルによって、 最終的には、メッセージ クライアントによる機能のレンダリング方法が制御されます。 ある機能が複数のチャンネルでサポートされていても、その機能をレンダリングする方法は、チャンネルごとに若干異なる可能性があります。 チャンネルがネイティブにサポートしていない機能がメッセージに含まれている場合、チャンネルはメッセージのコンテンツをテキストや静的な画像としてダウンレンダリングしようとする場合があり、クライアント上でのメッセージの外観に大きな影響を及ぼす可能性があります。 チャンネルが特定の機能をまったくサポートしない場合もあります。 たとえば、GroupMe クライアントでは入力インジケーターを表示できません。

## <a name="rich-user-controls"></a>リッチ ユーザー コントロール

**リッチ ユーザー コントロール**は、ボタン、画像、カルーセル、メニューなど、ボットがユーザーに提供する一般的な UI コントロールで、ユーザーはこのコントロールを使って選択肢や意図を伝えます。 ボットは UI コントロールのコレクションを使用してアプリを模倣したり、アプリ内に埋め込まれた状態で実行したりすることもできます。 アプリや Web サイトに埋め込まれているボットは、そのボットをホストしているアプリの機能を活用して、実質的にすべての UI コントロールを表すことができます。 

数十年にわたり、アプリケーションと Web サイトの開発者は、UI コントロールを使ってユーザーがアプリケーションとやり取りできるようにしてきました。この UI コントロールは、ボットでも非常に効果的です。 たとえば、単純な選択肢をユーザーに表示するには、ボタンが便利です。 **ホテル** というラベルが付いたボタンをクリックしてユーザーが "ホテル" と通信できれば、"ホテル" とタイプ入力するよりも、すばやく簡単に操作できます。 これは、タイプ入力よりもクリック操作が好まれるモバイル デバイスでは、特に当てはまります。

## <a name="cards"></a>カード

カードを使用すると、ユーザーにさまざまなビジュアル、オーディオ、選択可能なメッセージを提供し、会話フローを支援できます。 固定された項目セットからユーザーが選択する必要がある場合は、カードのカルーセルを表示できます。そのカードそれぞれに、画像、テキストの説明、および 1 つの選択ボタンが含まれています。 1 つの項目に対して一連の選択肢がある場合は、小さな 1 つの画像とボタンのコレクションを表示し、選択できるさまざまなオプションを示すことができます。 あるテーマについてさらに詳しい情報が求められた場合は、 カードによって、オーディオまたは動画出力を使った詳細情報や、ショッピングの明細を示す領収書を提供できます。 カードには、ユーザーとボットの間の会話を支援する非常に広範な用途があります。 使用するカードの種類は、アプリケーションのニーズによって決まります。 カードとそのアクション、および推奨されるいくつかの用途を詳しく見ていきましょう。 

Microsoft Bot Service のカードはプログラミング可能なオブジェクトで、さまざまなチャネルで認識されるリッチ ユーザー コントロールの標準化されたコレクションが格納されています。 次の表は、使用可能なカードの一覧です。また、各種カードの用途のベスト プラクティスも提案しています。

| カードの種類 | 例 | 説明 |
| ---- | ---- | ---- |
| AdaptiveCard | ![アダプティブ カードの画像](./media/adaptive-card.png) | JSON オブジェクトとしてレンダリングされるオープン カード交換形式。 通常はクロスチャネルのカード展開に使用されます。 カードは各ホスト チャネルの外患に適合します。 |
| AnimationCard | ![アニメーション カードの画像](./media/animation-card1.png) | アニメーション GIF または短い動画を再生できるカード。 |
| AudioCard | ![オーディオ カードの画像](./media/audio-card.png) | オーディオ ファイルを再生できるカード。 |
| HeroCard | ![ヒーロー カードの画像](./media/hero-card1.png) | 1 つの大きな画像、1 つまたは複数のボタン、およびテキストが含まれるカード。 通常は、ユーザーへの選択肢をビジュアルで強調表示するときに使用されます。 |
| ThumbnailCard | ![サムネイル カードの画像](./media/thumbnail-card.png) | 1 つのサムネイル画像、1 つまたは複数のボタン、およびテキストが含まれるカード。 通常は、ユーザーの選択肢を表すボタンをビジュアルで強調表示するときに使用されます。 |
| ReceiptCard | ![領収書カードの画像](./media/receipt-card1.png) | ボットからユーザーに領収書を提供できるようにするカード。 通常は、領収書に含める項目の一覧、税金と合計の情報、およびその他のテキストが含まれます。 |
| SignInCard | ![サインイン カードの画像](./media/sign-in-card.png) | ボットでユーザーのサインインを要求できるようにするカード。 通常は、テキストと、ユーザーがクリックしてサインイン プロセスを開始できる 1 つまたは複数のボタンが含まれます。 |
| SuggestedAction | ![推奨されるアクション カードの画像](./media/suggested-actions.png) | ユーザーの選択肢を表す一連のカード アクションをユーザーに示します。 推奨されるアクションのいずれかが選択されると、このカードは消えます。 |
| VideoCard | ![動画カードの画像](./media/video-card.png) | 動画を再生できるカード。 通常は、URL を開いて、使用可能な動画をストリーミングするときに使用されます。 |
| CardCarousel | ![カード カルーセルの画像](./media/card-carousel.png) | 水平方向にスクロール可能なカード コレクション。これにより、一連の選択肢をユーザーが容易に表示できます。|

カードを使用すると、ボットを一度設計するだけで、さまざまなチャネルで動作させることができます。 ただし、一部の種類のカードについては、一部のチャネルでは、まだ完全にはサポートされていません。 

ボットにカードを追加する手順の詳細については、[リッチ カード メディアの添付ファイルの追加](v4sdk/bot-builder-howto-add-media-attachments.md)に関するページと「[メッセージへの推奨されるアクションの追加](v4sdk/bot-builder-howto-add-suggested-actions.md)」を参照してください。 また、サンプル コードはこちら (カード: [C#](https://aka.ms/bot-cards-sample-code-cs)/[JS](https://aka.ms/bot-cards-sample-code-js)、アダプティブ カード: [C#](https://aka.ms/bot-adaptive-cards-sample-code)/[JS](https://aka.ms/bot-adaptive-cards-js-sample-code)、添付ファイル: [C#](https://aka.ms/bot-attachments-sample-code)/[JS](https://aka.ms/bot-attachments-js-sample-code)、推奨されるアクション: [C#](https://aka.ms/bot-suggested-actions-code)/[JS](https://aka.ms/bot-suggested-actions-js-code)) にも見つかります。



ボットを設計するときは、一般的な UI 要素を、"十分にスマート" ではないという理由で反射的に無視してはいけません。 [前に](~/bot-service-design-principles.md#designing-a-bot)説明したように、ボットは、ユーザーの問題をできるだけ迅速かつ簡単に、そして効果的に解決するよう設計する必要があります。 まず、自然言語の理解を組み込むという誘惑を退けましょう。これは不要なことが多く、無意味な複雑さが増します。

> [!TIP]
> 最初は、ボットがユーザーの問題を解決できるようにする最小限の UI コントロールを使用します。そして、そのコントロールでは不十分なときに、後から他の要素を追加します。


## <a name="text-and-natural-language-understanding"></a>テキストと自然言語の理解

ボットはユーザーからの**テキスト**入力を受け入れ、正規表現の一致、または <a href="https://www.luis.ai" target="_blank">LUIS</a> などの**自然言語の理解** API を使って、その入力の解析を試みることができます。 自然言語の理解が適切なソリューションであるかどうかは、ユーザー入力の種類によります。

場合によっては、ユーザーが**非常に具体的な質問に答える**ことがあります。 たとえば、ボットから "お名前は何ですか" と聞かれたユーザーは、"John" と名前だけ答えることも、"私の名前は John です" と文章で答えることもあります。

具体的な質問をすると、ボットに返されることが想定される妥当な答えの範囲が狭くなり、応答の解析および理解に必要なロジックの複雑さが減ります。 たとえば、"ご気分はいかがですか?" という自由回答式の大まかな質問について考えてみましょう。 このような質問に対して想定される答えの順列が多数であることを考えると、これを解釈する作業は非常に複雑です。

これに対し、"痛みを感じますか? はい/いいえ"、"どこに痛みを感じますか? 胸/頭/腕/脚" といった具体的な質問ならば、自然言語の理解を実装しなくてもボットが解析および解釈できる、より具体的な応答を引き出すことができますす。 

> [!TIP]
> 自然言語の理解機能がなくても応答を解析できる、できる限り具体的な質問を行ってください。 これによりボットが簡素化され、ボットがユーザーの意図を解釈する可能性が大きくなります。

  
また、ユーザーが**特定のコマンドをタイプ入力**する場合もあります。 たとえば、開発者が仮想マシンを管理できるようにする DevOps ボットは、"/STOP VM XYZ"、"/START VM XYZ" など、特定のコマンドを受け入れるように設計されていることがあります。 このような特定のコマンドを受け入れるようにボットを設計すると、優れたユーザー エクスペリエンスを実現できます。構文が学習しやすく、コマンドごとに期待される結果が明確であるためです。 また、正規表現を使用してユーザー入力を容易に解析できるため、ボットには自然言語の解釈機能は必要ありません。 

> [!TIP]
> ユーザーに対して特定のコマンドを要求するようにボットを設計すると、多くの場合、優れたユーザー エクスペリエンスを実現でき、自然言語の理解機能も不要になります。

  
"*ナレッジ ベース*" ボットまたは "*質問と回答*" ボットの場合は、ユーザーが**一般的な質問**を行う場合があります。 たとえば、何千ものドキュメントの内容に基づいて質問に答えることができるボットを想像してみてください。 <a href="https://qnamaker.ai" target="_blank">QnA Maker</a> と <a href="https://azure.microsoft.com/en-us/services/search/" target="_blank">Azure Search</a> は両方とも、この種類のシナリオ専用に設計されたテクノロジです。 詳細については、「[ナレッジ ボットを設計する](bot-service-design-pattern-knowledge-base.md)」を参照してください。

> [!TIP]
> データベース、Web ページ、またはドキュメントからの構造化データまたは非構造化データに基づいて質問に答えるボットを設計する場合は、自然言語の理解によって問題の解決を試みるのではなく、このシナリオに対応するように特別に設計されたテクノロジを使用することを検討してください。

  
また別のシナリオでは、ユーザーが**自然言語に基づいた単純な要求をタイプ入力**することがあります。 たとえば、ユーザーが "ペパロニ ピザが食べたい" または "自宅から 3 マイル以内に、営業中のベジタリアン レストランはありますか?" と入力する場合があります。 [LUIS.ai](https://www.luis.ai) などの自然言語の理解 API は、このようなシナリオに最適です。 

この API を使用すると、お使いのボットでユーザーのテキストの主要コンポーネントを抽出して、ユーザーの意図を特定できます。 ボットに自然言語の理解機能を実装する場合は、ユーザーが入力すると思われる詳細レベルに合った現実的な期待値を設定します。 

![ユーザーの応答](./media/bot-service-design-user-experience/buy-house.png)

> [!TIP]
> 自然言語モデルを構築するときは、ユーザーが最初のクエリで、必要な情報すべてを入力することを想定しないでください。 必要な情報を具体的に要求するようにボットを設計してください。ボットが必要に応じて質問を行うことで、ユーザーがそういった情報を入力するよう誘導するのです。 

  
## <a name="speech"></a>音声

ボットでは**音声**入出力を使用して、ユーザーとやり取りできます。 キーボードやモニターがないデバイスに対応するようにボットが設計されている場合、ユーザーとやり取りするには音声を使うしかありません。 

## <a name="choosing-between-rich-user-controls-text-and-natural-language-and-speech"></a>リッチ ユーザー コントロール、テキスト、自然言語、および音声のどれを選択するか

人がジェスチャ、声、記号を組み合わせて互いにコミュニケーションを取り合うように、ボットとユーザーのやり取りには、リッチ ユーザー コントロール、テキスト (自然言語を含む場合があります)、および音声の組み合わせを使用できます。 これらのコミュニケーション方法は一緒に使用できるため、特にどれか 1 つを選択する必要はありません。 

たとえば、レシピを提供する "料理ボット" があるとします。このボットでは、動画の再生や一連の画像を表示して手順を提供し、必要な作業について説明します。 レシピを実行しながら、レシピのページをめくるのを好むユーザーもいれば、音声でボットに質問したいユーザーもいるでしょう。 また、音声ではなく、デバイス画面をタッチしてボットを操作したい人もいるかもしれません。 ボットを設計するときは、サポートしようとしている特定のユース ケースを考慮して、ボットとのやり取りでユーザーが好みそうな方法に対応した UX 要素を組み込みます。 

